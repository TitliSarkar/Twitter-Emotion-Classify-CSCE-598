/** Here is a sample output for running the model for biLSTM. The outher models have similar outputs. **/

E:\Studies\Ph.D\Sem 5\Deep Learning\project\code
Train shape: 7102 7102
Validation shape: 1464 1464
Test shape: 2000 2000
All Models Loaded!
Max twitter length: 35
input_data shape: 10566
E:/Studies/Ph.D/Sem 5/Deep Learning/project/code/Emotion_Classification_Models_titli.py:191: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).
  if (token in w2v_model):{token_eb.append(w2v_model[token])}
E:/Studies/Ph.D/Sem 5/Deep Learning/project/code/Emotion_Classification_Models_titli.py:191: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).
  if (token in w2v_model):{token_eb.append(w2v_model[token])}
<class 'numpy.ndarray'> (7102, 35, 500)
<class 'numpy.ndarray'> (1464, 35, 500)
<class 'numpy.ndarray'> (2000, 35, 500)
Train embedding shape: (7102, 35, 500) 7102
Dev embedding shape: (1464, 35, 500) 1464
Test embedding shape: (2000, 35, 500) 2000
Number of output classes: 4
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
One-hot encoded labels shape (train, validation, test): (7102, 4) (1464, 4) (2000, 4)
500
Training size: (8566, 35, 500)
Test size: (2000, 35, 500)


Running bi-LSTM model.......
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        (None, None, 500)         0         
_________________________________________________________________
bidirectional_3 (Bidirection (None, 128)               289280    
_________________________________________________________________
dropout_15 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 4)                 516       
=================================================================
Total params: 289,796
Trainable params: 289,796
Non-trainable params: 0
_________________________________________________________________
Train on 8566 samples, validate on 2000 samples
Epoch 1/10
8566/8566 [==============================] - 23s 3ms/step - loss: 1.3529 - acc: 0.3352 - val_loss: 1.4331 - val_acc: 0.2435

Epoch 00001: val_loss improved from inf to 1.43315, saving model to twitter-emotion-bi_lstm.h5
Epoch 2/10
8566/8566 [==============================] - 15s 2ms/step - loss: 1.2280 - acc: 0.4696 - val_loss: 1.5795 - val_acc: 0.1925

Epoch 00002: val_loss did not improve
Epoch 3/10
8566/8566 [==============================] - 14s 2ms/step - loss: 1.1298 - acc: 0.5301 - val_loss: 1.7346 - val_acc: 0.1995

Epoch 00003: val_loss did not improve
Epoch 4/10
8566/8566 [==============================] - 16s 2ms/step - loss: 1.0741 - acc: 0.5542 - val_loss: 1.8142 - val_acc: 0.1950

Epoch 00004: val_loss did not improve
Epoch 5/10
8566/8566 [==============================] - 15s 2ms/step - loss: 1.0401 - acc: 0.5761 - val_loss: 1.8296 - val_acc: 0.1940

Epoch 00005: val_loss did not improve
Epoch 6/10
8566/8566 [==============================] - 15s 2ms/step - loss: 1.0157 - acc: 0.5838 - val_loss: 1.9996 - val_acc: 0.1880

Epoch 00006: val_loss did not improve
Epoch 7/10
8566/8566 [==============================] - 15s 2ms/step - loss: 0.9845 - acc: 0.6061 - val_loss: 2.0234 - val_acc: 0.1900

Epoch 00007: val_loss did not improve
Epoch 8/10
8566/8566 [==============================] - 15s 2ms/step - loss: 0.9525 - acc: 0.6145 - val_loss: 2.0575 - val_acc: 0.1865

Epoch 00008: val_loss did not improve
Epoch 9/10
8566/8566 [==============================] - 15s 2ms/step - loss: 0.9246 - acc: 0.6267 - val_loss: 2.1061 - val_acc: 0.1900

Epoch 00009: val_loss did not improve
Epoch 10/10
8566/8566 [==============================] - 15s 2ms/step - loss: 0.8885 - acc: 0.6458 - val_loss: 2.1912 - val_acc: 0.1810

Epoch 00010: val_loss did not improve

Confusion Matrix on test data [(4x4) for 4 output labels of 'anger', 'fear', 'joy', 'sadness']: 
[[183 156 56 105]
 [285 61 53 102]
 [101 25 289 86]
 [174 52 64 208]]

biLSTM F-score= 0.3646077928039411
biLSTM recall-score= 0.37095472909602484
